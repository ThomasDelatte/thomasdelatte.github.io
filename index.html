<!DOCTYPE html>
<html lang="en">
<head>
	<!-- Basic Metas -->
	<meta charset="utf-8">
	<title>Thomas Delatte</title>
	<meta name="description" content="Website and blog of Thomas Delatte, data scientist and lawyer from Brussels.">
	<meta name="author" content="Thomas Delatte">
	<link rel="author" href=""/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<!-- Open Graph -->
	<meta property="og:title" content="Thomas Delatte">
	<meta property="og:description" content="Website and blog of Thomas Delatte, data scientist and lawyer from Brussels.">
	<meta property="og:image" content="https://thomasdelatte.github.io/images/icons/avatar.png">
	<meta property="og:type" content="website">
	<meta property="og:url" content="https://thomasdelatte.github.io">

	<!-- Stylesheets and Web Fonts -->
	<link href="/theme/style.min.css" rel="stylesheet">
	<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Favicons -->
	<link rel="apple-touch-icon" sizes="180x180" href="/images/icons/apple-touch-icon.png">
	<link rel="icon" type="image/png" href="/images/icons/favicon-16x16.png" sizes="16x16">
	<link rel="icon" type="image/png" href="/images/icons/favicon-32x32.png" sizes="32x32">
	<meta name="theme-color" content="#FF8000">

	<meta name="msapplication-TileColor" content="#FF8000">
	<meta name="msapplication-TileImage" content="/images/icons/mstile-144x144.png">
	<meta name="msapplication-square70x70logo" content="/images/icons/mstile-small.png">
	<meta name="msapplication-square150x150logo" content="/images/icons/mstile-medium.png">
	<meta name="msapplication-wide310x150logo" content="/images/icons/mstile-wide.png">
	<meta name="msapplication-square310x310logo" content="/images/icons/mstile-large.png">

	<!--[if lt IE 9]>
	<script src="/theme/js/html5shiv.min.js"></script>
	<script src="/theme/js/respond.min.js"></script>
	<![endif]-->
</head>

<body>
	<div class="container">
		<aside>
			<a href="/"><img id="avatar" alt="Site Avatar" src="/images/icons/avatar.png"></a>
			<div id="name"><a href="/">Thomas Delatte</a></div>
			<div id="bio"></div>

			<div id="sidebar-links">
				<a href="/about/">About</a>&nbsp;|&nbsp;<a href="/portfolio/">Portfolio</a>
			</div>

			<div id="social">
				<a href="https://twitter.com/thomasdelatte" title="Twitter" class="icon fa fa-twitter"></a>
				<a href="https://github.com/ThomasDelatte" title="GitHub" class="icon fa fa-github"></a>
				<a href="https://www.linkedin.com/in/thomasdelatte" title="LinkedIn" class="icon fa fa-linkedin"></a>
			</div>

			<hr id="sidebar-divider">
		</aside>

		<article>
		<h1 class="title"><a href="2020/04/kmeans/" title="Clustering with K-Means">Clustering with K-Means</a></h1>
		<time class="date" datetime="2020-04-15 00:00:00+02:00">April 15, 2020</time>
		<div class="content summary">
			<p>Clustering with K-Means Introducing K-Means Clustering algorithms are a class of unsupervised machine learning models. They seek to learn an optimal division of group of points from the data features. Probably the simplest to understand is an algorithm called k-means clustering, which clusters the data into k number of clusters. This algorithm is widely used in practice: Anomaly Detection Image Segmentation Market Segmentation Genes/Species/Articles Clustering The idea behind the k-means algorithm is that an optimal clustering is a clustering in which the within-cluster variation is minimized. This within-cluster variation is usually defined as the squared Euclidean distance between the "cluster center" and each point. A data set is well separated into k clusters when: The centroid is the mean of all instances within the cluster. Each instance is closer to its own centroid than to other centroids. Those two assumptions are the foundation of the k-means algorithm. Before discovering this algorithm in more details, let's create a simple dataset to implement k-means.</p>
		</div>
<br>		<h1 class="title"><a href="2020/04/pulsars/" title="Pulsars Detection with HTRU2 Dataset">Pulsars Detection with HTRU2 Dataset</a></h1>
		<time class="date" datetime="2020-04-05 00:00:00+02:00">April 05, 2020</time>
		<div class="content summary">
			<p>Pulsars Detection with HTRU2 Dataset You can download the data here: R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar Candidate Selection: From simple filters to a new principled real-time classification approach MNRAS, 2016.. Introduction The HTRU2 dataset contains data about pulsars. As pulsars rotate, they emit their own slightly distinct radio wave pattern that can be identified in this way by large telescopes. However, other radio signals are also picked up in this way. It is essential to be able to identify which waves come from pulsars and which are noise. Indeed, almost all detections in practice are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find. The dataset contains a total of 17,897 samples of radio signals. This is an imbalanced dataset: 1,639 are real pulsar wave patterns while 16,258 are non-pulsar signals. There are eight features in the dataset to identify the pulsars. The first four features (Mean, Standard Deviation, Excess kurtosis and Skewness) are statistics of the pulse profile wave while the last four features are statistics about the DM-SNR (Dispersion Measure - Signal-to-Noise Ratio) curve obtained through the signal.</p>
		</div>
<br>		<h1 class="title"><a href="2020/04/quickdraw/" title="Computer Vision with Animals from QuickDraw">Computer Vision with Animals from QuickDraw</a></h1>
		<time class="date" datetime="2020-04-02 00:00:00+02:00">April 02, 2020</time>
		<div class="content summary">
			<p>Recognizing Animals from the QuickDraw Dataset The Quick Draw Dataset is a collection of 50 million drawings collected by Google, contributed by people drawing objects from 345 categories. You can browse the drawings here.</p>
		</div>
<br>		<h1 class="title"><a href="2020/03/keypoints/" title="Facial Keypoints Detection">Facial Keypoints Detection</a></h1>
		<time class="date" datetime="2020-03-25 00:00:00+01:00">March 25, 2020</time>
		<div class="content summary">
			<p>Facial Keypoints Detection Dataset Data comes from a Kaggle competition and can be found here. Objective Our objective is to predict keypoint positions on face images. This can be used as a building block in several applications, such as: tracking faces in images and video analysing facial expressions detecting dysmorphic facial signs for medical diagnosis biometrics / face recognition</p>
		</div>
	<div id="view-archives"><a href="/archive/">Older Posts &raquo;</a></div>
			<hr>
		</article>

		<footer>
			<p></p>
		</footer>
	</div>

	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-163901213-1', '');
		ga('send', 'pageview');
	</script>

</body>
</html>